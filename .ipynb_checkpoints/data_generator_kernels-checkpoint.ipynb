{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './exps/-f/hp_params.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b65b26a6cb11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-b65b26a6cb11>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0mexp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./exps/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;31m# sigmafs, sigmaerrs, sigmaxs = load_prior_definition(exp_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mhp_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/hp_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0msigma_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sigma_fs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0msigma_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sigma_xs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tomography/gp_backend.py\u001b[0m in \u001b[0;36mload_dic\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './exps/-f/hp_params.pkl'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import keras\n",
    "import pandas as pd\n",
    "import abc\n",
    "# from os import *\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# from gaussian_process import *\n",
    "import csv\n",
    "import glob\n",
    "from gp_backend import load_dic\n",
    "import os\n",
    "import math\n",
    "# from plots import plot_measurement\n",
    "from sklearn.model_selection import KFold\n",
    "from plotting import data_histogram\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, batch_size=2048, dim=208, shuffle=True,\n",
    "                 # no_sigmars=2, no_sigmaphis=2, no_sigmafs=2, no_sigmaerrs=2,\n",
    "                 no_batches_ep = 4096,\n",
    "                 # sigmafs=None, sigmaerrs=None, sigmalxs=None,\n",
    "                 no_good_sensors=208,\n",
    "                 exp_id='',\n",
    "                 epoch_size = 32,\n",
    "                 # shots=[],\n",
    "                 n_splits=2,):\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        \n",
    "        # self.fs = []\n",
    "        # self.xs = []\n",
    "        # self.errs = []\n",
    "        self.measurement_data = []\n",
    "        # shots = get_shots()\n",
    "        # self.shots = shots\n",
    "        # file_names = os.listdir('./shot_data/sxr')\n",
    "        self.n_splits = n_splits\n",
    "        # print(exp_id)\n",
    "        self.hp_dic = load_dic(exp_id + '/hp_params')\n",
    "        # print(self.hp_dic)\n",
    "        \n",
    "        self.epoch_size = epoch_size\n",
    "        self.generate_empty_buckets()\n",
    "        \n",
    "        self.sigma_fs = self.hp_dic['sigma_fs']\n",
    "        self.sigma_xs = self.hp_dic['sigma_xs']\n",
    "        self.sigma_errs = self.hp_dic['sigma_errs']\n",
    "        self.name = 'main'\n",
    "        # print(self.sigma_errs, type(self.sigma_errs))\n",
    "        # exit(0)\n",
    "        c = 0\n",
    "        cs = 0\n",
    "        # for counter, file_name in enumerate(file_names):\n",
    "            # shot_id = file_name[5:10]\n",
    "            # if int(shot_id) not in self.shots:# 30857, ]:#30294, 30310, 30357, 30372, 30376, 30400, 30405, 30406]:  #shots[:50] [30382,]  [30573, 30857]\n",
    "            #     continue\n",
    "            # c += 1\n",
    "        # np_file = np.load('./shot_data/sxr/' + file_name)\n",
    "        # measurement_data = np_file['data']#[:30]\n",
    "        # measurement_err = np_file['err']\n",
    "        errs = np.load(exp_id + '/reconstruction_sigma_errs.npy')\n",
    "        fs = np.load(exp_id + '/reconstruction_sigma_fs.npy')\n",
    "        xs = np.load(exp_id + '/reconstruction_sigma_xs.npy')\n",
    "        # ts = np.load(exp_id + '/reconstruction_times.npy')\n",
    "        measurement_data = np.load(exp_id + '/posterior_data_means.npy')\n",
    "        single_mclasses = np.load(exp_id + '/single_multiclasses.npy')\n",
    "        best_sigmas_grid = np.load(exp_id + '/best_sigmas_grid.npy')\n",
    "        # print(measurement_data.shape, fs.shape, xs.shape, errs.shape, errs.shape)\n",
    "        # assert measurement_data.shape[0] == errs.shape[0]\n",
    "        # self.measurement_data.extend(measurement_data)\n",
    "        data_histogram(best_sigmas_grid, self.sigma_fs, self.sigma_xs, self.sigma_errs, exp_id + '/data_histogram.pdf')\n",
    "        # exit(0)\n",
    "        for i in range(len(measurement_data)):\n",
    "            # print(i, len(self.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "            cs += 1\n",
    "            m = measurement_data[i]\n",
    "            # print(m.shape)\n",
    "            # exit(0)\n",
    "            # m_err = measurement_err[i]\n",
    "            # m_err[m_err!=float('inf')] = 1\n",
    "            # m_err[m_err==float('inf')] = 0\n",
    "            f = fs[i]\n",
    "            x = xs[i]\n",
    "            err = errs[i]\n",
    "            # t = ts[i]\n",
    "            \n",
    "            # print(f)\n",
    "            f_val = self.sigma_fs[np.argmax(f)]\n",
    "            x_val = self.sigma_xs[np.argmax(x)]\n",
    "            err_val = self.sigma_errs[np.argmax(err)]\n",
    "            \n",
    "            single_mclass = single_mclasses[i]\n",
    "            arg_f = np.argwhere(f==1)[0][0]\n",
    "            arg_x = np.argwhere(x==1)[0][0]\n",
    "            arg_err = np.argwhere(err==1)[0][0]\n",
    "            # print(np.expand_dims(np.ones(208)*err_val, axis=-1).shape)\n",
    "            # print(m.shape)\n",
    "            # exit(0)\n",
    "            self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['m'].append(m) #arctan np.ones(208)*err_val\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['m_err'].append(m_err)\n",
    "            self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['f'].append(f_val)\n",
    "            self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['x'].append(x_val)\n",
    "            self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['err'].append(err_val)\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['s&t'].append('#' + shot_id + '-' +  str(t))\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['s&t'].append('#' + shot_id + '-' +  str(t))\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['m'].append(m) #arctan np.ones(208)*err_val\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['m_err'].append(m_err)\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['f'].append(arg_f)\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['x'].append(arg_x)\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['err'].append(arg_err)\n",
    "            # self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['s&t'].append('#' + shot_id + '-' +  str(t))\n",
    "            self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['single_mclass'].append(single_mclass)\n",
    "            self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['uid'].append(cs)\n",
    "            \n",
    "            # print(len(self.buckets[str(arg_f) + '-' +  str(arg_x)+ '-' +  str(arg_err)]['f']))\n",
    "        print('Got', cs, ' data  samples. Hyperparameters were: f->', self.hp_dic['sigma_fs'], 'x', self.hp_dic['sigma_xs'], 'err', self.hp_dic['sigma_errs'])\n",
    "        # self.shuffle()\n",
    "        self.get_stats()\n",
    "        # exit(0)\n",
    "        kf = KFold(n_splits=self.n_splits)\n",
    "        s = 0\n",
    "        for k, v in self.buckets.items():\n",
    "            # print('in)')\n",
    "            if(len(v['m'])) != 0:\n",
    "                # print('in)')\n",
    "                data = self.buckets[k]['m']\n",
    "                for fold_ind, (train_indexes, test_indexes) in enumerate(kf.split(data)):\n",
    "                    # print(fold_ind, k, len(data), len(train_indexes), len(test_indexes))\n",
    "                    # exit(0)\n",
    "                    s += len(train_indexes)\n",
    "                    s += len(test_indexes)\n",
    "                    self.buckets[k]['split_inds_train'][fold_ind] = train_indexes\n",
    "                    self.buckets[k]['split_inds_test'][fold_ind] = test_indexes\n",
    "                    # print(train_indexes)\n",
    "                    # print(test_indexes)\n",
    "                    \n",
    "        # exit(0)\n",
    "        \n",
    "    def get_stats(self,):\n",
    "        print('------------------Printing stats for', self.name, 'generator------------------')\n",
    "        s = 0\n",
    "        print('f,x,err,count')\n",
    "        for k in self.buckets.keys():\n",
    "            s+=len(self.buckets[k]['m'])\n",
    "            print(k, len(self.buckets[k]['m']))\n",
    "        print('Total number of samples:', s)\n",
    "        \n",
    "    \n",
    "    def generate_empty_buckets(self,):\n",
    "        self.buckets = {}\n",
    "        for sigma_f in range(len(self.hp_dic['sigma_fs'])):\n",
    "            for sigma_x in range(len(self.hp_dic['sigma_xs'])):\n",
    "                for sigma_err in range(len(self.hp_dic['sigma_errs'])):\n",
    "                    # print(dict.fromkeys(np.arange(self.n_splits)))\n",
    "                    self.buckets[str(sigma_f) + '-' +  str(sigma_x)+ '-' +  str(sigma_err)] = {'m': [], 'f': [], 'x': [],  'err': [], 's&t':[], 'm_err':[], 'single_mclass':[], 'uid':[],\n",
    "                                                                     'split_inds_train': dict.fromkeys(np.arange(self.n_splits)),\n",
    "                                                                     'split_inds_test':dict.fromkeys(np.arange(self.n_splits))}\n",
    "    def shuffle(self,):\n",
    "        # print(len(self.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "        for k, v in self.buckets.items():\n",
    "            if(len(v['x'])) != 0:\n",
    "                aux = list(zip(v['x'], v['err'], v['f'], v['m'], v['single_mclass'], v['uid']))\n",
    "                random.shuffle(aux)\n",
    "                # print(v['m'][0].shape)\n",
    "                \n",
    "                x, err, f, m, single_mclass, uid = zip(*aux) #t, m_err\n",
    "                # print(type(m), len(m[0]), m)\n",
    "                # exit(0)\n",
    "                self.buckets[k]['x'] = list(x)\n",
    "                self.buckets[k]['err'] = list(err)\n",
    "                self.buckets[k]['f'] = list(f)\n",
    "                self.buckets[k]['m'] = list(m)\n",
    "                # self.buckets[k]['s&t'] = list(t)\n",
    "                # self.buckets[k]['m_err']= list(m_err)\n",
    "                self.buckets[k]['single_mclass']= list(single_mclass)\n",
    "                # self.buckets[k]['uid']= list(uid)\n",
    "        # print(len(self.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "        # exit(0)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.epoch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # start = index*self.batch_size\n",
    "        # end = (index+1)*self.batch_size\n",
    "        batch_in = {'m': [], 'm_err':[]}\n",
    "        batch_out = {'x': [], 'err': [],'f': [], 'single_mclass':[]}\n",
    "        batch_control = { 's&t': []}\n",
    "        counter = 0\n",
    "        # print(len(self.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "        # exit(0)\n",
    "        while counter < self.batch_size:\n",
    "            for k, v in self.buckets.items():\n",
    "                if(len(v['x'])) != 0:\n",
    "                    batch_in['m'].append(v['m'][0])\n",
    "                    # exit(0)\n",
    "                    v['m'].append(v['m'].pop(0))\n",
    "                    batch_out['x'].append(v['x'][0])\n",
    "                    batch_out['err'].append(v['err'][0])\n",
    "                    batch_out['f'].append(v['f'][0])\n",
    "                    batch_out['single_mclass'].append(v['single_mclass'][0])\n",
    "                    v['x'].append(v['x'].pop(0))\n",
    "                    v['err'].append(v['err'].pop(0))\n",
    "                    v['f'].append(v['f'].pop(0))\n",
    "                    v['single_mclass'].append(v['single_mclass'].pop(0))\n",
    "                    # batch_control['s&t'].append(v['s&t'][0])\n",
    "                    # v['s&t'].append(v['s&t'].pop(0))\n",
    "                    # batch_in['m_err'].append(v['m_err'][0])\n",
    "                    # v['m_err'].append(v['m_err'].pop(0))\n",
    "                    counter += 1\n",
    "                    \n",
    "                    \n",
    "        batch_in['m'] = np.expand_dims(np.asarray(batch_in['m']), axis=-1)[:self.batch_size]\n",
    "        \n",
    "        # batch_out['x'] = np.asarray(batch_out['x'])[:self.batch_size]\n",
    "        # err = np.asarray(batch_out['err'])[:self.batch_size]\n",
    "        # batch_out['err'] = err\n",
    "        # batch_out['f'] = np.asarray(batch_out['f'])[:self.batch_size]\n",
    "        \n",
    "        batch_out['single_mclass'] = np.asarray(batch_out['single_mclass'])[:self.batch_size]\n",
    "        batch_control['s&t'] = np.zeros(self.batch_size)\n",
    "        # print(batch_in['m'].shape)\n",
    "        # print(batch_out['single_mclass'].shape)\n",
    "        # exit(0)\n",
    "        return(batch_in['m'], batch_out['single_mclass']) #batch_control\n",
    "        # print(batch_in['input'].shape)\n",
    "        # print(batch_out['err'])\n",
    "        # exit(0)\n",
    "        # return (batch_in, batch_out['single_mclass'])\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            for item in (self[i] for i in range(len(self))):\n",
    "                yield item\n",
    "            # print('Generator has gone through all its data, reshuffling...')\n",
    "            self.shuffle()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        pass\n",
    "    \n",
    "    def get_all_items(self):\n",
    "        batch_in = {'m': [], 'm_err':[]}\n",
    "        batch_out = {'x': [], 'err': [],'f': [], 'single_mclass':[]}\n",
    "        batch_control = { 's&t': [], 'uid':[]}\n",
    "        # counter = 0\n",
    "        for k, v in self.buckets.items():\n",
    "            if(len(v['x'])) != 0:\n",
    "                batch_in['m'].extend(v['m'])\n",
    "                # v['m'].append(v['m'].pop(0))\n",
    "                batch_out['x'].extend(v['x'])\n",
    "                batch_out['err'].extend(v['err'])\n",
    "                batch_out['f'].extend(v['f'])\n",
    "                batch_out['single_mclass'].extend(v['single_mclass'])\n",
    "                # v['x'].append(v['x'].pop(0))\n",
    "                # v['err'].append(v['err'].pop(0))\n",
    "                # v['f'].append(v['f'].pop(0))\n",
    "                # v['single_mclass'].append(v['single_mclass'].pop(0))\n",
    "                batch_control['s&t'].extend(v['s&t'])\n",
    "                # v['s&t'].append(v['s&t'].pop(0))\n",
    "                batch_in['m_err'].extend(v['m_err'])\n",
    "                # v['m_err'].append(v['m_err'].pop(0))\n",
    "                # counter += 1\n",
    "                batch_control['uid'].extend(v['uid'])\n",
    "                    \n",
    "        batch_in['m'] = np.expand_dims(np.asarray(batch_in['m']), axis=-1)#[:self.batch_size]\n",
    "        batch_in['m_err'] = np.asarray(batch_in['m_err'])#[:self.batch_size]\n",
    "        # print(batch_in['m'].shape, batch_in['m_err'].shape)\n",
    "        # exit(0)\n",
    "        # batch_in['input'] = np.moveaxis(np.asarray([batch_in['m'], batch_in['m_err']])[:self.batch_size], 0, -1)\n",
    "        # batch_in['input'] = \n",
    "        batch_out['x'] = np.asarray(batch_out['x'])#[:self.batch_size]\n",
    "        err = np.asarray(batch_out['err'])#[:self.batch_size]\n",
    "        # ra = np.random.randn(self.batch_size)/10\n",
    "        # err += err*ra\n",
    "        # print(err)\n",
    "        batch_out['err'] = err\n",
    "        batch_out['f'] = np.asarray(batch_out['f'])#[:self.batch_size]\n",
    "        batch_out['single_mclass'] = np.asarray(batch_out['single_mclass'])#[:self.batch_size]\n",
    "        batch_control['s&t'] = np.asarray(batch_control['s&t'])#[:self.batch_size]\n",
    "        batch_control['uid'] = np.asarray(batch_control['uid'])\n",
    "        # return(batch_in, batch_out, batch_control)\n",
    "        # print(batch_in['m'].shape)\n",
    "        # print(batch_out['err'])\n",
    "        # exit(0)\n",
    "        return(batch_in['m'], batch_out['single_mclass'])\n",
    "        # return (batch_in, batch_out, batch_control)\n",
    "        \n",
    "    \n",
    "class TrainDataGenerator(DataGenerator):\n",
    "    def __init__(self, k_fold, main_generator = None):\n",
    "        self.hp_dic = main_generator.hp_dic\n",
    "        self.n_splits = main_generator.n_splits\n",
    "        self.generate_empty_buckets()\n",
    "        self.epoch_size = main_generator.epoch_size\n",
    "        self.batch_size = main_generator.batch_size\n",
    "        self.name = 'train'\n",
    "        # print(len(main_generator.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "        # exit(0)\n",
    "        for k, v in self.buckets.items():\n",
    "            # main_gen_len = len(main_generator.buckets[k]['m'])\n",
    "            # frac = math.floor(0.8*main_gen_len)\n",
    "            # print(k,'len', main_gen_len, frac)\n",
    "            # print(k, k_fold)\n",
    "            indices = main_generator.buckets[k]['split_inds_train'][k_fold]\n",
    "            # print(indices)\n",
    "            # v['m'] = main_generator.buckets[k]['m'][:frac]\n",
    "            # v['f'] = main_generator.buckets[k]['f'][:frac]\n",
    "            # v['x'] = main_generator.buckets[k]['x'][:frac]\n",
    "            # v['err'] = main_generator.buckets[k]['err'][:frac]\n",
    "            # v['s&t'] = main_generator.buckets[k]['s&t'][:frac]\n",
    "            for key in ['m', 'f', 'x', 'err', 'single_mclass', 'uid']: #'s&t', 'm_err', \n",
    "                # print(key, k , k_fold)\n",
    "                # print(len(np.asarray(main_generator.buckets[k][key])))\n",
    "                # print(indices)\n",
    "                \n",
    "                v[key] = np.asarray(main_generator.buckets[k][key])[indices]\n",
    "                # exit(0)\n",
    "            # v['m'] = main_generator.buckets[k]['m'][indices]\n",
    "            # v['f'] = main_generator.buckets[k]['f'][indices]\n",
    "            # v['x'] = main_generator.buckets[k]['x'][indices]\n",
    "            # v['err'] = main_generator.buckets[k]['err'][indices]\n",
    "            # v['s&t'] = main_generator.buckets[k]['s&t'][indices]\n",
    "        # print(len(self.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "        # print(len(main_generator.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "        # exit(0)\n",
    "        self.shuffle()\n",
    "        # self.get_stats()    \n",
    "    \n",
    "    def __str__(self,):\n",
    "        return 'train'\n",
    "    \n",
    "        \n",
    "class ValDataGenerator(DataGenerator):\n",
    "    def __init__(self, k_fold, main_generator = None):\n",
    "        self.hp_dic = main_generator.hp_dic\n",
    "        self.n_splits = main_generator.n_splits\n",
    "        self.generate_empty_buckets()\n",
    "        self.epoch_size = main_generator.epoch_size\n",
    "        self.batch_size = main_generator.batch_size\n",
    "        self.name = 'validation'\n",
    "        for k, v in self.buckets.items():\n",
    "            # main_gen_len = len(main_generator.buckets[k]['m'])\n",
    "            # frac = math.ceil(0.8*main_gen_len)\n",
    "            indices = main_generator.buckets[k]['split_inds_test'][k_fold]\n",
    "            \n",
    "            # v['m'] = main_generator.buckets[k]['m'][frac:]\n",
    "            # v['f'] = main_generator.buckets[k]['f'][frac:]\n",
    "            # v['x'] = main_generator.buckets[k]['x'][frac:]\n",
    "            # v['err'] = main_generator.buckets[k]['err'][frac:]\n",
    "            # v['s&t'] = main_generator.buckets[k]['s&t'][frac:]\n",
    "            for key in ['m', 'f', 'x', 'err', 'single_mclass', 'uid']: #'s&t', 'm_err', \n",
    "                v[key] = list(np.asarray(main_generator.buckets[k][key])[indices])\n",
    "            # v['m'] = main_generator.buckets[k]['m'][indices]\n",
    "            # v['f'] = main_generator.buckets[k]['f'][indices]\n",
    "            # v['x'] = main_generator.buckets[k]['x'][indices]\n",
    "            # v['err'] = main_generator.buckets[k]['err'][indices]\n",
    "            # v['s&t'] = main_generator.buckets[k]['s&t'][indices]\n",
    "            # print(indices)\n",
    "        # print(len(self.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "        # exit(0)\n",
    "        self.shuffle()\n",
    "        # self.get_stats()  \n",
    "    def __str__(self,):\n",
    "        return 'test'\n",
    "\n",
    "def main(args):\n",
    "  \n",
    "    # savedir=sys.argv[1]\n",
    "    \n",
    "    exp_id = './exps/' + args[1]\n",
    "    # sigmafs, sigmaerrs, sigmaxs = load_prior_definition(exp_id)\n",
    "    hp_dic = load_dic(exp_id + '/hp_params')\n",
    "    sigma_fs = hp_dic['sigma_fs']\n",
    "    sigma_xs = hp_dic['sigma_xs']\n",
    "    sigma_errs = hp_dic['sigma_errs']\n",
    "    # shots = list(hp_dic['shots'])#[:3]\n",
    "    # shots=get_shots()[:-11]\n",
    "    n_splits=2\n",
    "    params_random = {'dim': 208,\n",
    "                  'no_batches_ep': 256, \n",
    "                  'shuffle': True,\n",
    "                  'exp_id':exp_id,\n",
    "                  'batch_size': len(sigma_fs)*len(sigma_xs)*len(sigma_errs),\n",
    "                  # 'shots':shots,\n",
    "                  'n_splits':n_splits,\n",
    "                }\n",
    "    # print(params_random)\n",
    "    # exit(0)\n",
    "    \n",
    "    \n",
    "    mainGenerator = DataGenerator(**params_random)\n",
    "    # print(len(mainGenerator.buckets[str(0) + '-' +  str(0)+ '-' +  str(0)]['m']))\n",
    "    # exit(0)\n",
    "    # k_fold = 0\n",
    "    for k_fold in range(mainGenerator.n_splits):\n",
    "        train_generator = TrainDataGenerator(k_fold, mainGenerator)\n",
    "        train_gen = next(iter(train_generator))\n",
    "        val_generator = ValDataGenerator(k_fold, mainGenerator)\n",
    "        val_gen = next(iter(val_generator))\n",
    "        # print(gen)\n",
    "        # print('with the current batch size, each epoch should have', len(train_generator), 'steps')\n",
    "        # pr_measurement_mean = np.zeros(208)\n",
    "        \n",
    "        count = 0\n",
    "        for batch in train_gen:\n",
    "            if count == 1:\n",
    "                break\n",
    "            samples = []\n",
    "            samples_df = pd.DataFrame(columns=['input', 'f', 'x', 's&t'])\n",
    "            # inputs, targets, control = batch\n",
    "            inputs, targets = batch\n",
    "            # ms = inputs['m']\n",
    "            ms = inputs\n",
    "            # single_mclass = targets['single_mclass']\n",
    "            single_mclass = targets\n",
    "            # print('len batch', len(batch))\n",
    "            # for k in range(len(ms)):\n",
    "            #     print(sh_time[k], fs[k], xs[k])\n",
    "            # print(xs.shape)\n",
    "            for k in range(len(ms)):\n",
    "                # print(sh_time[k], fs[k], xs[k], errs[k], single_mclass[k])\n",
    "                # print(fs[k], xs[k], errs[k], single_mclass[k])\n",
    "                # print(single_mclass[k])\n",
    "                # shot, time = sh_time[k].split('-')\n",
    "                # plot_measurement(ms[k], m_err[k], 'no shot', 'no time')\n",
    "                # break\n",
    "                pass\n",
    "            count += 1\n",
    "            # print('finished batch')\n",
    "            # print(errs[0])\n",
    "            \n",
    "        # count = 0    \n",
    "        # for batch in val_gen:\n",
    "        #     if count == 1:\n",
    "        #         break\n",
    "        #     samples = []\n",
    "        #     samples_df = pd.DataFrame(columns=['input', 'f', 'x', 's&t'])\n",
    "        #     inputs, targets, control = batch\n",
    "        #     ms = inputs['m']\n",
    "        #     print(ms.shape)\n",
    "        #     # xs = targets['x']\n",
    "        #     # fs = targets['f']\n",
    "        #     # errs = targets['err']\n",
    "        #     # m_err = inputs['m_err']\n",
    "        #     # sh_time = control['s&t']\n",
    "        #     single_mclass = targets['single_mclass']\n",
    "        #     print('len batch', len(batch))\n",
    "        #     # for k in range(len(ms)):\n",
    "        #     #     print(sh_time[k], fs[k], xs[k])\n",
    "        #     for k in range(len(ms)):\n",
    "        #         # print(sh_time[k], fs[k], xs[k], errs[k], single_mclass[k])\n",
    "        #         # shot, time = sh_time[k].split('-')\n",
    "        #         # plot_measurement(ms[k], shot, time)\n",
    "        #         break\n",
    "        #     count += 1\n",
    "        #     print('finished batch')\n",
    "        #     # print(errs[0])\n",
    "        # \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d27a7d38377f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exp5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: main() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "main('exp5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
